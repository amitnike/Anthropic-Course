{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37f04e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load environment variables\n",
    "from dotenv import load_dotenv  \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad47467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create API client\n",
    "from anthropic import Anthropic\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32e89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper method to add user messages\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "#helper method to add assistant messages\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "#Make a request to the API\n",
    "def chat(messages,system=None,temperature=1.0,stop_sequences=[]):\n",
    "    params ={\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    response = client.messages.create(**params)\n",
    "    return response.content[0].text  # Return the text of the first message in the response\n",
    "\n",
    "#Usage of system Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc39a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(messages,stop_sequences=[\"```\"])\n",
    "    return json.loads(text)\n",
    "\n",
    "dataset = generate_dataset()\n",
    "\n",
    "dataset\n",
    "\n",
    "# Save the dataset to a file\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77557041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\"Merges the prompt and test case input, then returns the result\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case['task']}\n",
    "\n",
    "* Respond only with Python, JSON, or a plain Regex\n",
    "* Do not add any comments or commentary or explanation\n",
    "\n",
    "\"\"\"\n",
    "    message = []\n",
    "    add_user_message(message, prompt)\n",
    "    # Add the test case input as a code block..i.e. python, json, or regex\n",
    "    add_assistant_message(message, \"```code\")\n",
    "    output = chat(message, stop_sequences=[\"```\"])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e190ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_by_model(test_case, output):\n",
    "    # Create evaluation prompt\n",
    "    eval_prompt = \"\"\"\n",
    "    You are an expert code reviewer. Evaluate this AI-generated solution.\n",
    "    \n",
    "    Task: {task}\n",
    "    Solution: {solution}\n",
    "    \n",
    "    Provide your evaluation as a structured JSON object with:\n",
    "    - \"strengths\": An array of 1-3 key strengths\n",
    "    - \"weaknesses\": An array of 1-3 key areas for improvement  \n",
    "    - \"reasoning\": A concise explanation of your assessment\n",
    "    - \"score\": A number between 1-10\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ff303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to validate the output structure\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"calls the run_prompt function with the test case and grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "    # Here you would implement the grading logic based on the output\n",
    "    \n",
    "    # Grade the output\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "\n",
    "    score = (model_score + syntax_score) / 2\n",
    "    \n",
    "    return {\n",
    "        \"output\": output, \n",
    "        \"test_case\": test_case, \n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f84e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Runs the evaluation on the dataset and returns the results\"\"\"\n",
    "    results = []\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "    \n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5496ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 2.3333333333333335\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6c4bd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"Here's a JSON policy document that grants read-only access to the specific S3 bucket 'my-company-logs' for the specified principal:\\n\\n```json\\n{\\n  \\\"Version\\\": \\\"2012-10-17\\\",\\n  \\\"Statement\\\": [\\n    {\\n      \\\"Sid\\\": \\\"AllowReadOnlyAccessToMyCompanyLogs\\\",\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Principal\\\": {\\n        \\\"AWS\\\": \\\"arn:aws:iam::123456789012:user/log-reader\\\"\\n      },\\n      \\\"Action\\\": [\\n        \\\"s3:GetObject\\\",\\n        \\\"s3:GetObjectVersion\\\",\\n        \\\"s3:ListBucket\\\",\\n        \\\"s3:GetBucketLocation\\\"\\n      ],\\n      \\\"Resource\\\": [\\n        \\\"arn:aws:s3:::my-company-logs\\\",\\n        \\\"arn:aws:s3:::my-company-logs/*\\\"\\n      ]\\n    }\\n  ]\\n}\\n```\\n\\nThis policy document includes:\\n\\n- **Version**: Uses the latest policy language version (2012-10-17)\\n- **Principal**: Specifies the exact IAM user ARN provided\\n- **Actions**: Grants essential read-only permissions:\\n  - `s3:GetObject` - Download/read objects in the bucket\\n  - `s3:GetObjectVersion` - Read specific versions of objects (if versioning is enabled)\\n  - `s3:ListBucket` - List contents of the bucket\\n  - `s3:GetBucketLocation` - Get the bucket's AWS region\\n- **Resources**: Includes both the bucket itself and all objects within it using the wildcard (`/*`)\\n\\nThis policy can be attached as a bucket policy to the S3 bucket or as an identity-based policy to the IAM user, depending on your access management strategy.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a JSON policy document that grants read-only access to a specific S3 bucket named 'my-company-logs' for the principal 'arn:aws:iam::123456789012:user/log-reader'\",\n",
      "      \"format\": \"json\"\n",
      "    },\n",
      "    \"score\": 0,\n",
      "    \"reasoning\": \"I cannot provide a meaningful code review as the task description and solution code were not included in your request. To give you a proper evaluation, I would need to see both the specific programming task requirements and the AI-generated code solution. Please provide these details so I can assess the code's correctness, efficiency, readability, and adherence to best practices.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a Python function that extracts the file extension from an S3 object key:\\n\\n```python\\nimport os\\n\\ndef get_s3_file_extension(s3_key):\\n    \\\"\\\"\\\"\\n    Extract the file extension from an S3 object key.\\n    \\n    Args:\\n        s3_key (str): The S3 object key (path to the file)\\n    \\n    Returns:\\n        str: The file extension including the dot (e.g., '.txt', '.json', '.log')\\n             Returns empty string if no extension is found\\n    \\n    Examples:\\n        >>> get_s3_file_extension('folder/file.txt')\\n        '.txt'\\n        >>> get_s3_file_extension('logs/app.log')\\n        '.log'\\n        >>> get_s3_file_extension('data/users.json')\\n        '.json'\\n        >>> get_s3_file_extension('path/to/file')\\n        ''\\n    \\\"\\\"\\\"\\n    if not s3_key or not isinstance(s3_key, str):\\n        return ''\\n    \\n    # Use os.path.splitext to get the extension\\n    _, extension = os.path.splitext(s3_key)\\n    return extension\\n```\\n\\nHere's an alternative implementation without using the `os` module:\\n\\n```python\\ndef get_s3_file_extension_manual(s3_key):\\n    \\\"\\\"\\\"\\n    Extract the file extension from an S3 object key (manual implementation).\\n    \\n    Args:\\n        s3_key (str): The S3 object key (path to the file)\\n    \\n    Returns:\\n        str: The file extension including the dot (e.g., '.txt', '.json', '.log')\\n             Returns empty string if no extension is found\\n    \\\"\\\"\\\"\\n    if not s3_key or not isinstance(s3_key, str):\\n        return ''\\n    \\n    # Find the last dot in the string\\n    last_dot_index = s3_key.rfind('.')\\n    \\n    # If no dot found or dot is at the end, return empty string\\n    if last_dot_index == -1 or last_dot_index == len(s3_key) - 1:\\n        return ''\\n    \\n    # Extract everything from the last dot to the end\\n    extension = s3_key[last_dot_index:]\\n    \\n    # Make sure there are no path separators after the last dot\\n    # (to handle cases like \\\"file.txt/folder\\\")\\n    if '/' in extension:\\n        return ''\\n    \\n    return extension\\n```\\n\\nAnd here's a test function to demonstrate usage:\\n\\n```python\\ndef test_s3_extension_function():\\n    \\\"\\\"\\\"Test the S3 file extension function with various inputs.\\\"\\\"\\\"\\n    \\n    test_cases = [\\n        ('folder/file.txt', '.txt'),\\n        ('logs/application.log', '.log'),\\n        ('data/users.json', '.json'),\\n        ('images/photo.jpg', '.jpg'),\\n        ('documents/report.pdf', '.pdf'),\\n        ('backup/database.sql.gz', '.gz'),\\n        ('path/to/file', ''),\\n        ('file.txt/folder/', ''),\\n        ('hidden/.gitignore', ''),\\n        ('.env', ''),\\n        ('file.', ''),\\n        ('', ''),\\n        ('just_filename', ''),\\n        ('path/file.with.multiple.dots.csv', '.csv')\\n    ]\\n    \\n    print(\\\"Testing S3 file extension extraction:\\\")\\n    for s3_key, expected in test_cases:\\n        result = get_s3_file_extension(s3_key)\\n        status = \\\"\\u2713\\\" if result == expected else \\\"\\u2717\\\"\\n        print(f\\\"{status} '{s3_key}' -> '{result}' (expected: '{expected}')\\\")\\n\\n# Run the test\\nif __name__ == \\\"__main__\\\":\\n    test_s3_extension_function()\\n```\\n\\n**Key features of the solution:**\\n\\n1. **Input validation**: Checks if the input is a valid string\\n2. **Handles edge cases**: Empty strings, files without extensions, paths ending with folders\\n3. **Uses standard library**: The `os.path.splitext()` method is the most reliable way to extract file extensions\\n4. **Returns\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that takes an S3 object key as input and returns the file extension (e.g., '.txt', '.json', '.log')\",\n",
      "      \"format\": \"python\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution demonstrates a solid understanding of the sliding window algorithm and implements it correctly. The code is clean and readable, but could benefit from better error handling and documentation. The approach is efficient with O(n) time complexity, which is optimal for this problem.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"I'll create a regular expression to validate AWS IAM role ARNs. Let me break down the format and provide a comprehensive solution.\\n\\n## AWS IAM Role ARN Format Analysis\\n\\nThe format is: `arn:aws:iam::account-id:role/role-name`\\n\\n- `arn:aws:iam::` - Fixed prefix\\n- `account-id` - 12-digit AWS account ID\\n- `:role/` - Fixed separator\\n- `role-name` - Role name (can include paths)\\n\\n## Regular Expression Solutions\\n\\n### Basic Version\\n```regex\\n^arn:aws:iam::\\\\d{12}:role\\\\/[a-zA-Z0-9+=,.@_-]+$\\n```\\n\\n### Comprehensive Version (Recommended)\\n```regex\\n^arn:aws:iam::\\\\d{12}:role\\\\/(?:[a-zA-Z0-9+=,.@_-]+\\\\/)*[a-zA-Z0-9+=,.@_-]+$\\n```\\n\\n### Most Strict Version (Following AWS Naming Rules)\\n```regex\\n^arn:aws:iam::\\\\d{12}:role\\\\/(?:[a-zA-Z0-9_+=,.@-]{1,64}\\\\/)*[a-zA-Z0-9_+=,.@-]{1,64}$\\n```\\n\\n## Code Examples\\n\\n### JavaScript\\n```javascript\\nfunction validateIAMRoleARN(arn) {\\n    const pattern = /^arn:aws:iam::\\\\d{12}:role\\\\/(?:[a-zA-Z0-9+=,.@_-]+\\\\/)*[a-zA-Z0-9+=,.@_-]+$/;\\n    return pattern.test(arn);\\n}\\n\\n// Test examples\\nconsole.log(validateIAMRoleARN(\\\"arn:aws:iam::123456789012:role/MyRole\\\")); // true\\nconsole.log(validateIAMRoleARN(\\\"arn:aws:iam::123456789012:role/service/MyRole\\\")); // true\\nconsole.log(validateIAMRoleARN(\\\"arn:aws:iam::123456789012:user/MyUser\\\")); // false\\n```\\n\\n### Python\\n```python\\nimport re\\n\\ndef validate_iam_role_arn(arn):\\n    pattern = r'^arn:aws:iam::\\\\d{12}:role\\\\/(?:[a-zA-Z0-9+=,.@_-]+\\\\/)*[a-zA-Z0-9+=,.@_-]+$'\\n    return bool(re.match(pattern, arn))\\n\\n# Test examples\\nprint(validate_iam_role_arn(\\\"arn:aws:iam::123456789012:role/MyRole\\\"))  # True\\nprint(validate_iam_role_arn(\\\"arn:aws:iam::123456789012:role/service/MyRole\\\"))  # True\\nprint(validate_iam_role_arn(\\\"arn:aws:iam::123456789012:user/MyUser\\\"))  # False\\n```\\n\\n### Java\\n```java\\nimport java.util.regex.Pattern;\\n\\npublic class IAMRoleARNValidator {\\n    private static final Pattern PATTERN = Pattern.compile(\\n        \\\"^arn:aws:iam::\\\\\\\\d{12}:role\\\\\\\\/(?:[a-zA-Z0-9+=,.@_-]+\\\\\\\\/)*[a-zA-Z0-9+=,.@_-]+$\\\"\\n    );\\n    \\n    public static boolean isValidIAMRoleARN(String arn) {\\n        return PATTERN.matcher(arn).matches();\\n    }\\n    \\n    // Test\\n    public static void main(String[] args) {\\n        System.out.println(isValidIAMRoleARN(\\\"arn:aws:iam::123456789012:role/MyRole\\\")); // true\\n        System.out.println(isValidIAMRoleARN(\\\"arn:aws:iam::123456789012:role/service/MyRole\\\")); // true\\n    }\\n}\\n```\\n\\n## Pattern Breakdown\\n\\n```regex\\n^arn:aws:iam::\\\\d{12}:role\\\\/(?:[a-zA-Z0-\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a regular expression that validates AWS IAM role ARNs (format: arn:aws:iam::account-id:role/role-name)\",\n",
      "      \"format\": \"regex\"\n",
      "    },\n",
      "    \"score\": 0,\n",
      "    \"reasoning\": \"I cannot provide a meaningful evaluation without seeing the actual task description and solution code. To properly assess an AI-generated solution, I would need to examine the specific implementation, verify its correctness against the requirements, analyze its time/space complexity, check for proper error handling, and evaluate code quality factors like readability and maintainability.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
