{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37f04e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load environment variables\n",
    "from dotenv import load_dotenv  \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad47467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create API client\n",
    "from anthropic import Anthropic\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32e89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper method to add user messages\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "#helper method to add assistant messages\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "#Make a request to the API\n",
    "def chat(messages,system=None,temperature=1.0,stop_sequences=[]):\n",
    "    params ={\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    response = client.messages.create(**params)\n",
    "    return response.content[0].text  # Return the text of the first message in the response\n",
    "\n",
    "#Usage of system Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc39a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(messages,stop_sequences=[\"```\"])\n",
    "    return json.loads(text)\n",
    "\n",
    "dataset = generate_dataset()\n",
    "\n",
    "dataset\n",
    "\n",
    "# Save the dataset to a file\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77557041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\"Merges the prompt and test case input, then returns the result\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case['task']}\n",
    "\"\"\"\n",
    "    message = []\n",
    "    add_user_message(message, prompt)\n",
    "    output = chat(message)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e190ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_by_model(test_case, output):\n",
    "    # Create evaluation prompt\n",
    "    eval_prompt = \"\"\"\n",
    "    You are an expert code reviewer. Evaluate this AI-generated solution.\n",
    "    \n",
    "    Task: {task}\n",
    "    Solution: {solution}\n",
    "    \n",
    "    Provide your evaluation as a structured JSON object with:\n",
    "    - \"strengths\": An array of 1-3 key strengths\n",
    "    - \"weaknesses\": An array of 1-3 key areas for improvement  \n",
    "    - \"reasoning\": A concise explanation of your assessment\n",
    "    - \"score\": A number between 1-10\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b6b2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"calls the run_prompt function with the test case and grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "    # Here you would implement the grading logic based on the output\n",
    "    \n",
    "    # Grade the output\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "    \n",
    "    return {\n",
    "        \"output\": output, \n",
    "        \"test_case\": test_case, \n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f84e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Runs the evaluation on the dataset and returns the results\"\"\"\n",
    "    results = []\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "    \n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5496ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 4.666666666666667\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6c4bd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"Here's a Python function that extracts the bucket name from an S3 bucket ARN:\\n\\n```python\\ndef extract_bucket_name_from_arn(arn):\\n    \\\"\\\"\\\"\\n    Extract the bucket name from an S3 bucket ARN.\\n    \\n    Args:\\n        arn (str): S3 bucket ARN in the format 'arn:aws:s3:::bucket-name'\\n    \\n    Returns:\\n        str: The bucket name extracted from the ARN\\n    \\n    Raises:\\n        ValueError: If the ARN format is invalid\\n    \\\"\\\"\\\"\\n    if not isinstance(arn, str):\\n        raise ValueError(\\\"ARN must be a string\\\")\\n    \\n    if not arn:\\n        raise ValueError(\\\"ARN cannot be empty\\\")\\n    \\n    # Split the ARN by colons\\n    arn_parts = arn.split(':')\\n    \\n    # Validate ARN format\\n    if len(arn_parts) != 6:\\n        raise ValueError(\\\"Invalid ARN format. Expected format: 'arn:aws:s3:::bucket-name'\\\")\\n    \\n    if arn_parts[0] != 'arn':\\n        raise ValueError(\\\"ARN must start with 'arn'\\\")\\n    \\n    if arn_parts[1] != 'aws':\\n        raise ValueError(\\\"ARN must specify 'aws' as the partition\\\")\\n    \\n    if arn_parts[2] != 's3':\\n        raise ValueError(\\\"ARN must be for S3 service\\\")\\n    \\n    if arn_parts[3] != '':\\n        raise ValueError(\\\"Region field must be empty for S3 bucket ARNs\\\")\\n    \\n    if arn_parts[4] != '':\\n        raise ValueError(\\\"Account ID field must be empty for S3 bucket ARNs\\\")\\n    \\n    # Extract bucket name (last part after the final colon)\\n    bucket_name = arn_parts[5]\\n    \\n    if not bucket_name:\\n        raise ValueError(\\\"Bucket name cannot be empty\\\")\\n    \\n    return bucket_name\\n\\n\\n# Example usage and test cases\\nif __name__ == \\\"__main__\\\":\\n    # Test cases\\n    test_arns = [\\n        \\\"arn:aws:s3:::my-bucket\\\",\\n        \\\"arn:aws:s3:::my-test-bucket-123\\\",\\n        \\\"arn:aws:s3:::company.bucket-name_2023\\\"\\n    ]\\n    \\n    for arn in test_arns:\\n        try:\\n            bucket_name = extract_bucket_name_from_arn(arn)\\n            print(f\\\"ARN: {arn}\\\")\\n            print(f\\\"Bucket Name: {bucket_name}\\\")\\n            print(\\\"-\\\" * 40)\\n        except ValueError as e:\\n            print(f\\\"Error processing ARN '{arn}': {e}\\\")\\n    \\n    # Test invalid ARNs\\n    invalid_arns = [\\n        \\\"arn:aws:s3:us-east-1::my-bucket\\\",  # Has region\\n        \\\"arn:aws:ec2:::instance\\\",           # Wrong service\\n        \\\"invalid-arn\\\",                      # Completely invalid\\n        \\\"arn:aws:s3:::\\\",                    # Missing bucket name\\n    ]\\n    \\n    print(\\\"\\\\nTesting invalid ARNs:\\\")\\n    for arn in invalid_arns:\\n        try:\\n            bucket_name = extract_bucket_name_from_arn(arn)\\n            print(f\\\"Unexpectedly succeeded for: {arn} -> {bucket_name}\\\")\\n        except ValueError as e:\\n            print(f\\\"Correctly rejected '{arn}': {e}\\\")\\n```\\n\\nHere's also a simpler version if you don't need extensive validation:\\n\\n```python\\ndef extract_bucket_name_simple(arn):\\n    \\\"\\\"\\\"\\n    Simple function to extract bucket name from S3 ARN.\\n    \\n    Args:\\n        arn (str): S3 bucket ARN in the format 'arn:aws:s3:::bucket-name'\\n    \\n    Returns:\\n        str: The bucket name\\n    \\\"\\\"\\\"\\n    return arn.split(':')[-1]\\n\\n\\n# Example usage\\nif __name__ == \\\"__main__\\\":\\n    arn = \\\"arn:aws:s\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that takes an S3 bucket ARN and extracts just the bucket name from it. The function should handle ARNs in the format 'arn:aws:s3:::bucket-name' and return only the bucket name portion.\"\n",
      "    },\n",
      "    \"score\": 0,\n",
      "    \"reasoning\": \"I cannot provide a meaningful evaluation without seeing the actual task description and solution code. To give you a proper assessment, I would need to see the specific problem statement and the AI-generated code solution to analyze its correctness, efficiency, readability, and adherence to best practices.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a JSON object representing an IAM policy that grants read-only access to the 'my-data-bucket' S3 bucket:\\n\\n```json\\n{\\n  \\\"Version\\\": \\\"2012-10-17\\\",\\n  \\\"Statement\\\": [\\n    {\\n      \\\"Sid\\\": \\\"ListBucketAccess\\\",\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": \\\"s3:ListBucket\\\",\\n      \\\"Resource\\\": \\\"arn:aws:s3:::my-data-bucket\\\"\\n    },\\n    {\\n      \\\"Sid\\\": \\\"GetObjectAccess\\\",\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": \\\"s3:GetObject\\\",\\n      \\\"Resource\\\": \\\"arn:aws:s3:::my-data-bucket/*\\\"\\n    }\\n  ]\\n}\\n```\\n\\n**Explanation of the policy components:**\\n\\n- **Version**: Specifies the policy language version (2012-10-17 is the current version)\\n- **Statement**: Contains an array of permission statements\\n\\n**First Statement (ListBucketAccess):**\\n- **Sid**: Statement identifier for easier management\\n- **Effect**: \\\"Allow\\\" grants the specified permissions\\n- **Action**: \\\"s3:ListBucket\\\" allows listing the contents of the bucket\\n- **Resource**: Points to the bucket itself (`arn:aws:s3:::my-data-bucket`)\\n\\n**Second Statement (GetObjectAccess):**\\n- **Sid**: Statement identifier for the object access\\n- **Effect**: \\\"Allow\\\" grants the specified permissions\\n- **Action**: \\\"s3:GetObject\\\" allows downloading/reading objects\\n- **Resource**: Points to all objects within the bucket (`arn:aws:s3:::my-data-bucket/*`)\\n\\nThis policy provides the minimum necessary permissions for read-only access to the specified S3 bucket and follows the principle of least privilege.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a JSON object representing an IAM policy that grants read-only access to a specific S3 bucket called 'my-data-bucket'. The policy should allow ListBucket and GetObject actions only for that bucket and its contents.\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution demonstrates solid programming fundamentals with clean, readable code that handles most edge cases appropriately. The algorithm choice is efficient and well-implemented. However, it could benefit from more robust input validation, better documentation through comments, and consideration of alternative approaches for different use cases.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Looking at the pattern of valid AWS region names, I can see they follow a specific structure:\\n- Geographic area (us, eu, ap, etc.)\\n- Cardinal direction (east, west, south, southeast, etc.)\\n- Availability zone number (1, 2, 3, etc.)\\n- All separated by hyphens\\n\\nHere's a regular expression that matches valid AWS region names:\\n\\n```regex\\n^(us|eu|ap|sa|ca|af|me)-(north|south|east|west|northeast|northwest|southeast|southwest|central)-\\\\d+$\\n```\\n\\nLet me break this down:\\n\\n- `^` - Start of string\\n- `(us|eu|ap|sa|ca|af|me)` - Geographic areas:\\n  - `us` - United States\\n  - `eu` - Europe\\n  - `ap` - Asia Pacific\\n  - `sa` - South America\\n  - `ca` - Canada\\n  - `af` - Africa\\n  - `me` - Middle East\\n- `-` - Literal hyphen\\n- `(north|south|east|west|northeast|northwest|southeast|southwest|central)` - Directions\\n- `-` - Literal hyphen\\n- `\\\\d+` - One or more digits\\n- `$` - End of string\\n\\n**Test cases:**\\n\\n\\u2705 **Valid matches:**\\n- `us-east-1`\\n- `eu-west-2` \\n- `ap-southeast-1`\\n- `ca-central-1`\\n- `af-south-1`\\n- `me-south-1`\\n\\n\\u274c **Invalid (won't match):**\\n- `us-east` (missing number)\\n- `invalid-region` (invalid geographic area)\\n- `us_east_1` (uses underscores instead of hyphens)\\n- `us-east-` (missing number)\\n- `europe-west-1` (should be `eu`, not `europe`)\\n\\nThis regex covers all current AWS regions and should handle most valid AWS region naming patterns while rejecting invalid formats.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a regular expression that matches valid AWS region names. The regex should match regions like 'us-east-1', 'eu-west-2', 'ap-southeast-1', but reject invalid formats like 'us-east', 'invalid-region', or 'us_east_1'.\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution demonstrates a solid understanding of dynamic programming principles and implements Kadane's algorithm correctly. The core logic is sound and efficient. However, it would benefit from more robust error handling and documentation to make it production-ready. The algorithm properly handles arrays with all negative numbers by returning the least negative value.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
